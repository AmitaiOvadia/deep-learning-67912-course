# -*- coding: utf-8 -*-
"""example_VICReg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jHE4aEI9oykYPxd5jgYyY_PIYjdeqJhb
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

from torchvision import transforms
import torch
import torch.nn as nn
import torchvision
from torchvision.models import resnet18
from torch.utils.data import Subset
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
!pip install hnswlib
import hnswlib

!pip install faiss-cpu
import faiss
# %matplotlib inline
ENCODER_PATH = "enc_40_mu_25.pth"

device="cuda"
batch_size = 256
transform = transforms.Compose(
    [transforms.ToTensor()])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2, drop_last=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

class Encoder(nn.Module):
    def __init__(self, D=128, device='cuda'):
        super(Encoder, self).__init__()
        self.resnet = resnet18(pretrained=False)
        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=1)
        self.resnet.maxpool = nn.Identity()
        self.resnet.fc = nn.Linear(512, 512)
        self.fc = nn.Sequential(nn.BatchNorm1d(512), nn.ReLU(inplace=True), nn.Linear(512, D))

    def forward(self, x):
        x = self.resnet(x)
        x = self.fc(x)
        return x

    def encode(self, x):
        return self.forward(x)

class LinearProbing(nn.Module):
    def __init__(self, encoder, D=128, C=10):
        # D is the encoded latent space and C is the number of classes
        super(LinearProbing, self).__init__()
        self.encoder = encoder
        self.fc = nn.Linear(D, C)
    def forward(self, x):
        x = self.encoder(x)
        x = self.fc(x)
        return x

def show_and_save_graph(X, label, title,xlabel='batches'):
  plt.plot(X, label=label)
  plt.legend()
  plt.xlabel(xlabel)
  plt.ylabel('Loss')
  plt.title(title)
  plt.show()

import torch.optim as optim

def test(model, testloader):
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            labels = labels.to(device)
            outputs = model(images.to(device))
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print('Accuracy of the network on the test images: %d %%' % (
        100 * correct / total))
    accuracy = 100 * correct / total
    return accuracy

def train_and_test_LP():
  path_of_encoder = ENCODER_PATH
  encoder = torch.load(path_of_encoder)
  encoder.eval() # Set the model to evaluation mode
  for param in encoder.parameters():
    # Set the requires_grad attribute to False
    param.requires_grad = False
  LP_model = LinearProbing(encoder).to(device)
  print(sum(p.numel() for p in LP_model.parameters() if p.requires_grad))
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.Adam(LP_model.parameters())


  # train the linear probing model
  losses_LP = []
  num_epochs = 2
  for epoch in range(num_epochs) :  # loop over the dataset multiple times
      num_batches_train = len(trainloader)
      for batch_num, batch in tqdm(enumerate(trainloader, 0), total=len(trainloader)):
          B, labels = batch
          pred_labels = LP_model(B.to(device))
          loss = criterion(pred_labels, labels.to(device))
          losses_LP.append(loss.item())
          loss.backward()
          optimizer.step()
          optimizer.zero_grad()
  acc = test(LP_model, testloader)
  show_and_save_graph(losses_LP, "Linear Probing Loss", f"Linear Probing Loss, accuracy {acc}")
train_and_test_LP()

"""# closest retrievals for a sample from each class"""

def get_representations(encoder, dataloader):
  representations = []
  class_labels = []
  for batch_idx, (batch, labels) in enumerate(dataloader):
      encoded_data = encoder.encode(batch.to(device))
      for i in range(len(encoded_data)):
          representations.append(encoded_data[i].tolist())
          class_labels.append(labels[i].tolist())
  representations = torch.tensor(representations)
  class_labels = torch.tensor(class_labels)
  print(f"representations is of size {representations.size()} and the labels are of size {class_labels.size()}")
  return representations, class_labels


# start with the
def disply_nearest_neighbors(encoder, reps):
  class_images = {}
    # Loop through the dataset and add one image from each class to the dictionary
  for i in range(len(testset)):
      image, label = testset[i]
      if label not in class_images:
          class_images[label] = image
      if len(class_images) == 10: break
  all_neighbors_images = []
  all_far_neghbors_images = []

  for label, image in class_images.items():
      encoded = encoder(image.unsqueeze(0).to(device))[0].unsqueeze(0).to(device)
      distances = torch.cdist(encoded, reps.to(device))
      # Find the indices of the 5 nearest neighbors
      _, indices = distances.topk(k=5, largest=False)
      inds = indices[0].cpu().detach().numpy()
      # Get the 5 nearest neighbors
      image = image.numpy().transpose([1,2,0])
      neighbor_images = [image]
      for i in inds:
          neighbor_img = testset[i][0].numpy().transpose([1,2,0])
          neighbor_images.append(neighbor_img)
      all_neighbors_images.append(neighbor_images)

      # far neighbors
      _, far_indices = distances.topk(k=5, largest=True)
      far_inds = far_indices[0].cpu().detach().numpy()
      # Get the 5 nearest neighbors
      far_neighbor_images = [image]
      for i in far_inds:
          far_neighbor_img = testset[i][0].numpy().transpose([1,2,0])
          far_neighbor_images.append(far_neighbor_img)
      all_far_neghbors_images.append(far_neighbor_images)

  # plot the close neighbors
  num_classes = len(classes)
  num_images_per_row = 6
  fig, axs = plt.subplots(nrows=num_classes, ncols=num_images_per_row, figsize=(15, 15))
  print(len(all_neighbors_images), len(all_neighbors_images[0]))
  # Loop over each row and column and display the image
  for i in range(num_classes):
      for j in range(num_images_per_row):
          axs[i,j].imshow(all_neighbors_images[i][j])
          axs[i,j].axis('off')
  plt.show()



def find_the_neighbors():
    # encoder with var loss
    path_of_encoder = ENCODER_PATH
    encoder = torch.load(path_of_encoder)
    encoder.eval() # Set the model to evaluation mode

    reps_with_var, labels_var = get_representations(encoder, testloader)

    disply_nearest_neighbors(encoder, reps_with_var)


find_the_neighbors()